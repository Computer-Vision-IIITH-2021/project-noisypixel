{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import h5py\n",
    "\n",
    "# Network building stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torchmetrics\n",
    "import torch.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/home2/sdokania/all_projects/project-noisypixel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import *\n",
    "from src.dataset.dataloader import OccupancyNetDatasetHDF\n",
    "from src.trainer import ONetLit\n",
    "from src.utils import Config, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting sexperiment path as : /home2/sdokania/all_projects/occ_artifacts/initial\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config.data_root = \"/ssd_scratch/cvit/sdokania/processed_data/hdf_data/\"\n",
    "config.batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c_dim': 128,\n",
       " 'h_dim': 128,\n",
       " 'p_dim': 3,\n",
       " 'data_root': '/ssd_scratch/cvit/sdokania/processed_data/hdf_data/',\n",
       " 'batch_size': 32,\n",
       " 'output_dir': '/home2/sdokania/all_projects/occ_artifacts/',\n",
       " 'exp_name': 'initial',\n",
       " 'encoder': 'efficientnet-b0',\n",
       " 'decoder': 'decoder-cbn',\n",
       " 'exp_path': '/home2/sdokania/all_projects/occ_artifacts/initial',\n",
       " 'lr': 0.0003}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "onet = ONetLit(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "net = ONetLit.load_from_checkpoint(\"../occ_artifacts/efficient_cbn_bs_64_full_data/lightning_logs/version_1/checkpoints/epoch=28-step=13919.ckpt\", cfg=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OccupancyNetDatasetHDF(config.data_root, mode=\"val\", num_points=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img, test_pts, test_gt = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_3d_grid(bb_min, bb_max, shape):\n",
    "    ''' Makes a 3D grid.\n",
    "    Args:\n",
    "        bb_min (tuple): bounding box minimum\n",
    "        bb_max (tuple): bounding box maximum\n",
    "        shape (tuple): output shape\n",
    "    '''\n",
    "    size = shape[0] * shape[1] * shape[2]\n",
    "\n",
    "    pxs = torch.linspace(bb_min[0], bb_max[0], shape[0])\n",
    "    pys = torch.linspace(bb_min[1], bb_max[1], shape[1])\n",
    "    pzs = torch.linspace(bb_min[2], bb_max[2], shape[2])\n",
    "\n",
    "    pxs = pxs.view(-1, 1, 1).expand(*shape).contiguous().view(size)\n",
    "    pys = pys.view(1, -1, 1).expand(*shape).contiguous().view(size)\n",
    "    pzs = pzs.view(1, 1, -1).expand(*shape).contiguous().view(size)\n",
    "    p = torch.stack([pxs, pys, pzs], dim=1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vg = make_3d_grid((-0.5,)*3, (0.5,)*3, (32,)*3)\n",
    "vg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(test_img.unsqueeze(0), vg.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = net.net.encoder(test_img.unsqueeze(0)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([621, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = dist.Bernoulli(logits=out)\n",
    "vg[p.probs.flatten() > 0.5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4032, -0.0161, -0.0161],\n",
       "        [-0.4032, -0.0161,  0.0161],\n",
       "        [-0.4032, -0.0161,  0.0484],\n",
       "        ...,\n",
       "        [ 0.3387, -0.0161,  0.0484],\n",
       "        [ 0.3710, -0.0161, -0.0161],\n",
       "        [ 0.3710, -0.0161,  0.0161]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_p = vg[p.probs.flatten() > 0.5]\n",
    "good_p.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "outs = net.net.decoder(good_p.unsqueeze(0), c)\n",
    "outs = outs.sum()\n",
    "outs.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(621, 3)\n"
     ]
    }
   ],
   "source": [
    " ni = -good_p.grad\n",
    "ni = ni / torch.norm(ni, dim=-1, keepdim=True)\n",
    "ni = ni.squeeze(0).cpu().numpy()\n",
    "print(ni.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../point_vals\", good_p.detach().numpy())\n",
    "np.save(\"../normal_vals\", ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onet(torch.randn(1, 3, 224, 224), torch.randn(1, 1024, 3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTensorBoardLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msave_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mversion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_graph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdefault_hp_metric\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Log to local file system in `TensorBoard <https://www.tensorflow.org/tensorboard>`_ format.\n",
       "\n",
       "Implemented using :class:`~torch.utils.tensorboard.SummaryWriter`. Logs are saved to\n",
       "``os.path.join(save_dir, name, version)``. This is the default logger in Lightning, it comes\n",
       "preinstalled.\n",
       "\n",
       "Example:\n",
       "    >>> from pytorch_lightning import Trainer\n",
       "    >>> from pytorch_lightning.loggers import TensorBoardLogger\n",
       "    >>> logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
       "    >>> trainer = Trainer(logger=logger)\n",
       "\n",
       "Args:\n",
       "    save_dir: Save directory\n",
       "    name: Experiment name. Defaults to ``'default'``. If it is the empty string then no per-experiment\n",
       "        subdirectory is used.\n",
       "    version: Experiment version. If version is not specified the logger inspects the save\n",
       "        directory for existing versions, then automatically assigns the next available version.\n",
       "        If it is a string then it is used as the run-specific subdirectory name,\n",
       "        otherwise ``'version_${version}'`` is used.\n",
       "    log_graph: Adds the computational graph to tensorboard. This requires that\n",
       "        the user has defined the `self.example_input_array` attribute in their\n",
       "        model.\n",
       "    default_hp_metric: Enables a placeholder metric with key `hp_metric` when `log_hyperparams` is\n",
       "        called without a metric (otherwise calls to log_hyperparams without a metric are ignored).\n",
       "    prefix: A string to put at the beginning of metric keys.\n",
       "    \\**kwargs: Additional arguments like `comment`, `filename_suffix`, etc. used by\n",
       "        :class:`SummaryWriter` can be passed as keyword arguments in this logger.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TensorBoardLogger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "# Define the trainer object\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # auto_scale_batch_size='binsearch',\n",
    "    logger=logger,\n",
    "    min_epochs=1,\n",
    "    max_epochs=1,\n",
    "    default_root_dir=config.output_dir,\n",
    "    log_every_n_steps=10,\n",
    "    progress_bar_refresh_rate=5,\n",
    "    # precision=16,\n",
    "    # stochastic_weight_avg=True,\n",
    "    # track_grad_norm=2,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    check_val_every_n_epoch=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type      | Params\n",
      "-----------------------------------\n",
      "0 | net  | OccNetImg | 4.7 M \n",
      "-----------------------------------\n",
      "4.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 M     Total params\n",
      "18.802    Total estimated model params size (MB)\n",
      "/home2/sdokania/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be5bd3972cc484e9a772aa6b6c302dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72161166ebf474bbe886f867d35c361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.fit(onet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = OccupancyNetDatasetHDF(config.data_root, mode=\"val\")\n",
    "vdl = torch.utils.data.DataLoader(vd, batch_size=100, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([100, 3, 137, 137]) torch.Size([100, 1024, 3]) torch.Size([100, 1024])\n",
      "torch.Size([71, 3, 137, 137]) torch.Size([71, 1024, 3]) torch.Size([71, 1024])\n"
     ]
    }
   ],
   "source": [
    "for ix in vdl:\n",
    "    print(ix[0].shape, ix[1].shape, ix[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/ssd_scratch/cvit/sdokania/hdf_data/hdf_data/04256520_bdfcf2086fafb0fec8a04932b17782af.h5\"\n",
    "hf = h5py.File(fname, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['camera', 'images']>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
