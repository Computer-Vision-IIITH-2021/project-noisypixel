{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0650cc49-b6a9-4d41-8000-162918edc0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import h5py\n",
    "\n",
    "# Network building stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b17279-9fc3-48c8-8857-7313f7a9246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home2/sdokania/all_projects/project-noisypixel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c113081b-0dae-4889-ae96-31704a8b130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import *\n",
    "from src.dataset.dataloader import OccupancyNetDatasetHDF\n",
    "from src.trainer import ONetLit\n",
    "from src.utils import Config, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db21aba-9f44-4fed-b8aa-e7aef11a7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ca1d12-41bc-4c70-81cc-f5bb694428a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home2/sdokania/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f033cfe0a040f7a610e8909dbe711e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "onet = ONetLit(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc99d5c8-1bf4-4517-b048-6c69adae8f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff3042-543d-48b5-9123-4a1031c7db78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec46acf-6788-4450-906e-aa6acd7eacf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1234_d18592d9615b01bbbc0909d98a1ff2b4.hdf5', '1234_d18f2aeae4146464bd46d022fd7d80aa.hdf5', '1234_d199612c22fe9313f4fb6842b3610149.hdf5', '1234_d1a887a47991d1b3bc0909d98a1ff2b4.hdf5', '1234_d1a8e79eebf4a0b1579c3d4943e463ef.hdf5', '1234_d1b1c13fdec4d69ccfd264a25791a5e1.hdf5', '1234_d1b28579fde95f19e1873a3963e0d14.hdf5', '1234_d1b407350e61150942d79310bc7e47b3.hdf5', '1234_d1cdd239dcbfd018bbf3143b1cb6076a.hdf5', '1234_d1d308692cb4b6059a6e43b878d5b335.hdf5']\n"
     ]
    }
   ],
   "source": [
    "f = open(\"/ssd_scratch/cvit/sdokania/Shapenet3D/ShapeNet/02691156/test.lst\", \"r\")\n",
    "data = [\"{}_{}.hdf5\".format(1234, ix) for ix in f.read().split()[:10]]\n",
    "f.close()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "086509ad-52b9-4d92-ab6e-cefd70105df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OccupancyNetDatasetHDF(Dataset):\n",
    "    \"\"\"Occupancy Network dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, num_points=1024, default_transform=True, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "            num_points (int): Number of points to sample in the object point cloud from the data\n",
    "                on a sample.\n",
    "            mode (str): Which data split do we want among train, test and val\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.num_points = num_points\n",
    "        self.mode = mode\n",
    "        self.files = []\n",
    "        \n",
    "        # Save the files\n",
    "        f = open(os.path.join(self.root_dir, \"{}.lst\".format(self.mode)), 'r')\n",
    "        self.files = f.read().split()\n",
    "        f.close()\n",
    "            \n",
    "        # If not transforms have been provided, apply default imagenet transform\n",
    "        if transform is None and default_transform:\n",
    "            self.transform = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch the file path and setup image folder paths\n",
    "        req_path = self.files[idx]\n",
    "        file_path = os.path.join(self.root_dir, req_path)\n",
    "\n",
    "        # Load the h5 file\n",
    "        hf = h5py.File(file_path, 'r')\n",
    "        \n",
    "        # [NOTE]: the notation [()] below is to extract the value from HDF5 file\n",
    "        # get all images and randomly pick one\n",
    "        all_imgs = hf['images'][()]\n",
    "        random_idx = int(np.random.random()*all_imgs.shape[0])\n",
    "        \n",
    "        # Fetch the image we need\n",
    "        image = all_imgs[random_idx]\n",
    "        \n",
    "        # Get the points and occupancies\n",
    "        points = hf['points']['points'][()]\n",
    "        occupancies = np.unpackbits(hf['points']['occupancies'][()])\n",
    "\n",
    "        # Sample n points from the data\n",
    "        selected_idx = np.random.permutation(np.arange(points.shape[0]))[:self.num_points]\n",
    "\n",
    "        # Use only the selected indices and pack everything up in a nice dictionary\n",
    "        final_image = torch.from_numpy(image).float().transpose(1, 2).transpose(0, 1) / image.max()\n",
    "        final_points = torch.from_numpy(points[selected_idx]).float()\n",
    "        final_gt = torch.from_numpy(occupancies[selected_idx]).float()\n",
    "        \n",
    "        # Close the hdf file\n",
    "        hf.close()\n",
    "        \n",
    "        # Apply any transformation necessary\n",
    "        if self.transform:\n",
    "            final_image = self.transform(final_image)\n",
    "\n",
    "        return [final_image, final_points, final_gt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00823d51-37fc-4e87-b966-d144121b7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/ssd_scratch/cvit/sdokania/hdf_shapenet/hdf_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff1da7e5-27ae-49be-a193-9b66c3850e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = OccupancyNetDatasetHDF(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5f10aca-773b-4a81-85c8-43780d26ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = train_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0785eddc-896e-4855-a9ab-b9ba60c34b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 137, 137]), torch.Size([1024, 3]), torch.Size([1024]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[0].shape, op[1].shape, op[2].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
